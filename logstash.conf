input {
  beats {
    port => 5044
  }
  syslog {
    port => 514
    add_field => { "type" => "rsyslog" }
  }
  tcp {
    port  => 9999
    codec => json_lines
  }
  log4j {
    port => 4560
    type => "log4j"
  }
}

filter {

  if [type] == "log4j" {
    mutate {
      gsub => [
	"host", ":\d+", ""
      ]
    }
  }

  if [type] == "jetty_log" {

    if [host] in ["10.12.89.16","10.12.89.17"] {
       mutate {
         update => { "program" => "sanban-%{program}" }
       }
     }

    if [level] == "ERROR" {
      mutate {
        add_field => {
          "gsub_message" => "%{message}"
        }
      }
      mutate {
        gsub => [
          "gsub_message", "\n.*", ""
        ]
      }
      fingerprint {
        method => "SHA1"
        key => "key"
        source => ["gsub_message"]
      }
    }
  }

   if [type] == "mysql-sql-error" {

     if "SHOW SLAVE STATUS" in [message] {
        drop { }
     }

     grok {
       patterns_dir => "/etc/logstash/patterns"
       match => { "message" => "%{SQLERROR}" }
     }
     mutate {
       remove_field => [ "message[0]" ]
     }
     date {
       match => [ "timestamp", "YYYY-MM-dd HH:mm:ss","YYYY-MM-dd  HH:mm:ss" ]
       remove_field => "timestamp"
     }
   }

  if [type] == "mysql-slow-query" {

    csv {
      columns => [ "timestamp", "user_host", "query_time", "lock_time",
                   "rows_sent", "rows_examined", "db", "last_insert_id",
                   "insert_id", "server_id", "sql_text", "thread_id", "rows_affected" ]
    } 

   # convert various fields to integer
    mutate { 
      convert => { "rows_sent" => "integer" } 
      convert => { "rows_examined" => "integer" } 
      convert => { "last_insert_id" => "integer" } 
      convert => { "insert_id" => "integer" } 
      convert => { "server_id" => "integer" } 
      convert => { "thread_id" => "integer" } 
      convert => { "rows_affected" => "integer" } 
    }

   # convert start_time to @timestam
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSSSSS" ]
      remove_field => [ "timestamp" ]
    }

   # remove original message
    mutate { remove_field => [ "message" ] }

   # remove milliseconds
    mutate {
      gsub => [
        "query_time", "(.*\.)(\d)(\d)\d+", "\1\2\3",
        "lock_time", "(.*\.)(\d)(\d)\d+", "\1\2\3"
      ]
    }

    mutate {
      gsub => [
        "sql_text", "\nSET timestamp=\d+?;\n", "",
        "sql_text", "\nuse [a-zA-Z0-9\-\_]+?;", "",
        "sql_text", "\n# Time: \d+\s+\d+:\d+:\d+", "",
        "sql_text", "\n/usr/bin/mysql.+$", "",
        "sql_text", "\nTcp port:.+$", "",
        "sql_text", "\nTime .+$", ""
      ]
    }

   # gsub \n string to null
   mutate { gsub => ["sql_text", "\\r", "\
" ] }

   # gsub \r string to null
   mutate { gsub => ["sql_text", "\\n", "\
" ] }

   mutate { gsub => ["sql_text", "\\$", "" ] }


    fingerprint {
      method => "SHA1"
      key => "key"
      source => [ "sql_text" ]
    }


    # normalize query_time from HH::mm::ss.SSSSSS to seconds
     ruby { code => "event.set('query_time' , event.get('query_time') ? event.get('query_time').split(':').inject(0){|a, m| a = a * 60 + m.to_f} : 0)"}

    # normalize lock_time from HH:mm:ss to seconds
     ruby { code => "event.set('lock_time' , event.get('lock_time') ? event.get('lock_time').split(':').inject(0){|a, m| a = a * 60 + m.to_f} : 0)" }

  } 

  if [type] == "redis-log" {
    grok {
      patterns_dir => "/etc/logstash/patterns"
      match => { "message" => "%{REDISLOG}" }
    }
    mutate {
      gsub => [
       "loglevel", "\.", "debug",
       "loglevel", "\-", "verbose",
       "loglevel", "\*", "notice",
       "loglevel", "\#", "warring",
       "role","X","sentinel",
       "role","C","RDB/AOF writing child",
       "role","S","slave",
       "role","M","master"
      ]
    }
    date {
       match => [ "timestamp" , "dd MMM HH:mm:ss.SSS" ]
       target => "@timestamp"
       remove_field => [ "timestamp" ]
    }
  }

  if [type] == "linux-audit" {
    grok {
      patterns_dir => "/etc/logstash/patterns"
      break_on_match => false
      match => { "message" => ["%{AUDITAVC}",
                               "%{AUDIT}"] }
      add_tag => ["selinux_audit"]
    }

   if [audit_type] == "AVC" {
     kv { prefix => "audit_avc_"
       source => audit_avc_msg
     }
    } else {
      kv { prefix => "audit_%{[audit_type]}_"
        source => audit_msg
      }
    }
    date {
      match => [ "audit_epoch", "UNIX" ]
    }
  }

  if [type] == "analyze-access" {
    grok {
      patterns_dir => "/etc/logstash/patterns"
      match => { "message" => "%{ANALYZE}" }
    }
    if [params] {
      kv {
        field_split => ",?"
        source => "params"
      }
    }
    date {
      match => [ "date" , "yyyy-MM-dd HH:mm:ss.SSS" ]
    }
  }
  if [type] == "jetty-app-audit" {
    grok {
      patterns_dir => "/etc/logstash/patterns"
      match => { "message" => "%{JETTYAUDIT}" }
    }
    if [params] {
      kv {
        field_split => ",?"
        source => "params"
      }
    }
    if [source] =~ /\/API/ {
      mutate {
        add_field => { "mode" => "API"}
      }
    } else {
      mutate {
        add_field => { "mode" => "ENT"}
      }
    }
    date {
      match => [ "date" , "yyyy-MM-dd HH:mm:ss.SSS" ]
    }
  }
  if [type] == "nginx-access" {
   json {
     source => "message"
    }
    geoip { source => "remote_addr"
      target => "geoip"
    }
    mutate {
      convert => { "request_time" => "float" }
      convert => { "upstream_response_time" => "float" }
      convert => { "upstream_header_time" => "float" }
      convert => { "upstream_connect_time" => "float" }
      convert => { "body_bytes_sent" => "integer" }
      convert => { "bytes_sent" => "integer" }
      convert => { "upstream_bytes_received" => "integer" }
    }
    useragent {
      source => http_user_agent
    }
    fingerprint {
      method => "SHA1"
      key => "key"
      source => [ "uri" ]
    }
  }
  if [type] == "jetty-performance-audit" {
    grok {
      patterns_dir => "/etc/logstash/patterns"
      match => { "message" => "%{PERFORMANCE}" }
    }
    if [params] {
      kv {
        field_split => ",?"
        source => "params"
      }
    }
    date {
      match => [ "date" , "yyyy-MM-dd HH:mm:ss.SSS" ]
      remove_field => [ "timestamp" ]
    }
    mutate {
      convert => { "executeTime" => "float" }
    }
  }

  if [type] == "nginx-error" {
    grok {
      patterns_dir => "/etc/logstash/patterns"
      match => { "message" => ["%{NGINXERROR1}",
                               "%{NGINXERROR2}"] }
    }
    date {
      match => [ "timestamp" , "yyyy/MM/dd HH:mm:ss" ]
      timezone => 'Asia/Shanghai'
    }
  }

  if [type] == "jetty-enterprise-audit" {
    grok {
      patterns_dir => "/etc/logstash/patterns"
      match => { "message" => "%{JETTYAUDIT}" }
    }
    if [params] {
      kv {
        field_split => ",?"
        source => "params"
      }
    }
    date {
      match => [ "date" , "yyyy-MM-dd HH:mm:ss.SSS" ]
    }
  }
}
output {
  if [type] == "jetty_log" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-jetty-log-log-%{+YYYY-MM}"
    }
  }
  if [type] == "linux-audit" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-linux-audit-log-%{+YYYY-MM}"
    }
  }
  if [type] == "rsyslog" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-linux-rsyslog-log-%{+YYYY-MM}"
    }
  }
  if [type] == "redis-log" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-redis-log-%{+YYYY-MM}"
    }
  }
  if [type] == "mysql-slow-query" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-mysql-slow-query-%{+YYYY-MM}"
    }
  }
  if [type] == "log4j" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-log4j-log-%{+YYYY-MM}"
    }
  }
  if [type] == "mysql-sql-error" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-mysql-sql-error-log-%{+YYYY-MM}"
    }
  }
  if [type] == "nginx-access" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-nginx-access-%{+YYYY-MM}"
    }
  }
  if [type] == "nginx-error" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-nginx-error-%{+YYYY-MM}"
    }
  }
  if [type] == "analyze-access" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-analyze-access-%{+YYYY-MM}"
    }
    csv {
      fields => ["date","companyCode","userName","userId","companyShortName","clickButtonName","version","authority"]
      path => "/var/log/analyze/csv-analyze-%{+YYYY-MM-dd}.csv"
    }
  }
  if [type] == "jetty-performance-audit" {
    stdout { codec => rubydebug }
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-jetty-performance-audit-log-%{+YYYY-MM}"
    }
  }
   if [type] == "jetty-app-audit" {
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-jetty-app-audit-access-%{+YYYY-MM}"
    }
    csv {
      fields => ["date","mode","business_type","caller","companyCode","companyName","userId","userName"]
      path => "/var/log/app/csv-app-audit-%{+YYYY-MM-dd}.csv"
    }
  }
  if [type] == "jetty-enterprise-audit" {
#    stdout { codec => rubydebug }
    elasticsearch {
      hosts => ["10.12.89.11:9200"]
      index => "logstash-jetty-enterprise-audit-access-%{+YYYY-MM}"
    }
    csv {
      fields => ["date","companyCode","companyName","userId","userName","userIpAddress","requestUrl","urlDes"]
      path => "/var/log/enterprise/csv-enterprise-audit-%{+YYYY-MM-dd}.csv"
    }
  }
}
